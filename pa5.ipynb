{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Programming Assignment 5: Embeddings! \n",
    "\n",
    "Can you write a program to answer quiz questions?  \n",
    "\n",
    "Do you ever wish you could write a program to take quizzes or tests for you? In this assignment, you’ll do just that! In particular, you’ll leverage word embeddings to write a program that can answer various multiple choice and true/false quiz questions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Embeddings\n",
    "You’ll be using subset of ~4k 50-dimensional GloVe embeddings trained on Wikipedia articles. The GloVe (Global Vectors) model learns vector representations for words by looking at global word-word co-occurrence statistics in a body of text and learning vectors such that their dot product is proportional to the probability of the corresponding words co-occuring in a piece of text. The GloVe model was developed right here at Stanford, and if you’re curious you can read more about it [here](https://nlp.stanford.edu/projects/glove/)!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Couldn't find program: 'bash'\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "\n",
    "if [[ ! -d \"./data\" ]]\n",
    "then\n",
    "    echo \"Missing extra files (this probably means you're running on Google Colab). Downloading...\"\n",
    "    git clone https://github.com/cs124/pa5-embeddings.git\n",
    "    cp -r ./pa5-embeddings/{data,quizlet.py} .\n",
    "fi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'gensim'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[83], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Do not modify this cell, please just run it!\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mquizlet\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\HP\\Downloads\\pa5-embeddings-main\\pa5-embeddings-main\\quizlet.py:14\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcollections\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m defaultdict\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m---> 14\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgensim\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mscripts\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mglove2word2vec\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m glove2word2vec\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgensim\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeyedvectors\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m KeyedVectors\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnltk\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'gensim'"
     ]
    }
   ],
   "source": [
    "# Do not modify this cell, please just run it!\n",
    "import quizlet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Your Mission\n",
    "The assignment consists of five parts."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1: Synonyms\n",
    "For this section, your goal is to answer questions of the form:\n",
    "\n",
    "```\n",
    "  What is a synonym for warrior?  \n",
    "  a) soldier  \n",
    "  b) sailor  \n",
    "  c) pirate  \n",
    "  d) spy  \n",
    "```\n",
    "\n",
    "You are given as input a word and a list of candidate choices. Your goal is to return the choice you think is the synonym. You’ll first implement two similarity metrics - euclidean distance and cosine similarity - then leverage them to answer the multiple choice questions!\n",
    "\n",
    "Specifically, you will implement the following 4 functions:\n",
    "\n",
    "* **euclidean_distance()**: calculate the euclidean distance between two vectors. Note: you’ll only use this metric in Part 1. For the rest of the assignment, you'll only use cosine similarity.\n",
    "* **cosine_similarity()**: calculate the cosine similarity between two vectors. You’ll be using this helper function throughout the other parts of the assignment as well, so you’ll want to get it right!\n",
    "* **find_synonym()**: given a word, a list of 4 candidate choices, and which similarity metric to use, return which word you think is the synonym! The function takes in `comparison_metric` as a parameter: if its value is `euc_dist`, you'll use Euclidean distance as the similarity metric; if its value is `cosine_sim`, you'll use cosine similarity as the metric.\n",
    "* **part1_written()**: you’ll find that finding synonyms with word embeddings works quite well, especially when using cosine similarity as the metric. However, it’s not perfect. In this function, you’ll look at a question that your `find_synonyms()` function (using cosine similarity) gets wrong, and answer why you think this might be the case. Please return your answer as a string in this function.\n",
    "\n",
    "Note: for the rest of the assignment, you'll only use cosine similarity as the comparison metric. You won't use the euclidean distance function anymore.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def cosine_similarity(v1, v2):\n",
    "    '''\n",
    "    Calculates and returns the cosine similarity between vectors v1 and v2\n",
    "    Arguments:\n",
    "        v1 (np.array), v2 (np.array): vectors\n",
    "    Returns:\n",
    "        cosine_sim (float): the cosine similarity between v1, v2\n",
    "    '''\n",
    "    cosine_sim = 0\n",
    "    #########################################################\n",
    "    ## TODO: calculate cosine similarity between v1, v2    ##\n",
    "    #########################################################\n",
    "\n",
    "    cosine_sim = np.dot(v1, v2) / (np.linalg.norm(v1) * np.linalg.norm(v2))\n",
    "\n",
    "    #########################################################\n",
    "    ## End TODO                                            ##\n",
    "    #########################################################\n",
    "    return cosine_sim   \n",
    "\n",
    "def euclidean_distance(v1, v2):\n",
    "    '''\n",
    "    Calculates and returns the euclidean distance between v1 and v2\n",
    "\n",
    "    Arguments:\n",
    "        v1 (np.array), v2 (np.array): vectors\n",
    "\n",
    "    Returns:\n",
    "        euclidean_dist (float): the euclidean distance between v1, v2\n",
    "    '''\n",
    "    euclidean_dist = 0\n",
    "    #########################################################\n",
    "    ## TODO: calculate euclidean distance between v1, v2   ##\n",
    "    #########################################################\n",
    "\n",
    "    euclidean_dist = np.linalg.norm(v1 - v2)\n",
    "\n",
    "    #########################################################\n",
    "    ## End TODO                                           ##\n",
    "    #########################################################\n",
    "    return euclidean_dist                 \n",
    "\n",
    "def find_synonym(word, choices, embeddings, comparison_metric):\n",
    "    '''\n",
    "    Answer a multiple choice synonym question! Namely, given a word w \n",
    "    and list of candidate answers, find the word that is most similar to w.\n",
    "    Similarity will be determined by either euclidean distance or cosine\n",
    "    similarity, depending on what is passed in as the comparison_metric.\n",
    "\n",
    "    Arguments:\n",
    "        word (str): word\n",
    "        choices (List[str]): list of candidate answers\n",
    "        embeddings (Dict[str, np.array]): map of words to their embeddings\n",
    "        comparison_metric (str): either 'euc_dist' or 'cosine_sim'. \n",
    "            This indicates which metric to use - either euclidean distance or cosine similarity.\n",
    "            With euclidean distance, we want the word with the lowest euclidean distance.\n",
    "            With cosine similarity, we want the word with the highest cosine similarity.\n",
    "\n",
    "    Returns:\n",
    "        answer (str): the word in choices most similar to the given word\n",
    "    '''\n",
    "    answer = None\n",
    "    word_vec = embeddings[word]\n",
    "    best_choice = None\n",
    "    best_score = float('-inf') if comparison_metric == 'cosine_sim' else float('inf')\n",
    "    #########################################################\n",
    "    ## TODO: find synonym                                  ##\n",
    "    #########################################################\n",
    "\n",
    "    for choice in choices:\n",
    "        choice_vec = embeddings[choice]\n",
    "        if comparison_metric == 'cosine_sim':\n",
    "            score = cosine_similarity(word_vec, choice_vec)\n",
    "            if score > best_score:\n",
    "                best_score = score\n",
    "                best_choice = choice\n",
    "        elif comparison_metric == 'euc_dist':\n",
    "            score = euclidean_distance(word_vec, choice_vec)\n",
    "            if score < best_score:\n",
    "                best_score = score\n",
    "                best_choice = choice\n",
    "    answer = best_choice\n",
    "\n",
    "    #########################################################\n",
    "    ## End TODO                                            ##\n",
    "    ######################################################### \n",
    "    return answer\n",
    "\n",
    "def part1_written():\n",
    "    '''\n",
    "    Finding synonyms using cosine similarity on word embeddings does fairly well!\n",
    "    However, it's not perfect. In particular, you should see that it gets the last\n",
    "    synonym quiz question wrong (the true answer would be positive):\n",
    "\n",
    "    30. What is a synonym for sanguine?\n",
    "        a) pessimistic\n",
    "        b) unsure\n",
    "        c) sad\n",
    "        d) positive\n",
    "\n",
    "    What word does it choose instead? In 1-2 sentences, explain why you think \n",
    "    it got the question wrong.\n",
    "    \n",
    "    See the cell below for the code to run for this part\n",
    "    '''\n",
    "    #########################################################\n",
    "    ## TODO: replace string with your answer               ##\n",
    "    ######################################################### \n",
    "    answer = \"\"\"\n",
    "    TODO fill this in\n",
    "    \"\"\"\n",
    "    #########################################################\n",
    "\n",
    "    answer = \"\"\"\n",
    "\n",
    "    The model chooses 'pessimistic' instead of 'positive' because word embeddings are based on context in large corpora. \n",
    "    It might be that 'sanguine' is more often used in contexts similar to 'pessimistic' than 'positive', \n",
    "    leading to higher similarity with 'pessimistic' in this case.\n",
    "    \"\"\"\n",
    "\n",
    "    ## End TODO                                            ##\n",
    "    ######################################################### \n",
    "    return answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": [
     "exploration"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best synonym for 'warrior' (cosine similarity): soldier\n",
      "Best synonym for 'warrior' (euclidean distance): soldier\n",
      "\n",
      "    The model chooses 'pessimistic' instead of 'positive' because word embeddings are based on context in large corpora. \n",
      "    It might be that 'sanguine' is more often used in contexts similar to 'pessimistic' than 'positive', \n",
      "    leading to higher similarity with 'pessimistic' in this case.\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def cosine_similarity(v1, v2):\n",
    "    '''\n",
    "    Calculates and returns the cosine similarity between vectors v1 and v2.\n",
    "    Arguments:\n",
    "        v1 (np.array), v2 (np.array): vectors\n",
    "    Returns:\n",
    "        cosine_sim (float): the cosine similarity between v1, v2\n",
    "    '''\n",
    "    cosine_sim = np.dot(v1, v2) / (np.linalg.norm(v1) * np.linalg.norm(v2))\n",
    "    return cosine_sim\n",
    "\n",
    "def euclidean_distance(v1, v2):\n",
    "    '''\n",
    "    Calculates and returns the euclidean distance between v1 and v2.\n",
    "    Arguments:\n",
    "        v1 (np.array), v2 (np.array): vectors\n",
    "    Returns:\n",
    "        euclidean_dist (float): the euclidean distance between v1, v2\n",
    "    '''\n",
    "    euclidean_dist = np.linalg.norm(v1 - v2)\n",
    "    return euclidean_dist\n",
    "\n",
    "def find_synonym(word, choices, embeddings, comparison_metric):\n",
    "    '''\n",
    "    Answer a multiple choice synonym question! Namely, given a word w \n",
    "    and list of candidate answers, find the word that is most similar to w.\n",
    "    Similarity will be determined by either euclidean distance or cosine\n",
    "    similarity, depending on what is passed in as the comparison_metric.\n",
    "\n",
    "    Arguments:\n",
    "        word (str): word\n",
    "        choices (List[str]): list of candidate answers\n",
    "        embeddings (Dict[str, np.array]): map of words to their embeddings\n",
    "        comparison_metric (str): either 'euc_dist' or 'cosine_sim'. \n",
    "            This indicates which metric to use - either euclidean distance or cosine similarity.\n",
    "            With euclidean distance, we want the word with the lowest euclidean distance.\n",
    "            With cosine similarity, we want the word with the highest cosine similarity.\n",
    "\n",
    "    Returns:\n",
    "        answer (str): the word in choices most similar to the given word\n",
    "    '''\n",
    "    word_vec = embeddings[word]\n",
    "    best_choice = None\n",
    "    best_score = float('-inf') if comparison_metric == 'cosine_sim' else float('inf')\n",
    "\n",
    "    for choice in choices:\n",
    "        choice_vec = embeddings[choice]\n",
    "        if comparison_metric == 'cosine_sim':\n",
    "            score = cosine_similarity(word_vec, choice_vec)\n",
    "            if score > best_score:\n",
    "                best_score = score\n",
    "                best_choice = choice\n",
    "        elif comparison_metric == 'euc_dist':\n",
    "            score = euclidean_distance(word_vec, choice_vec)\n",
    "            if score < best_score:\n",
    "                best_score = score\n",
    "                best_choice = choice\n",
    "\n",
    "    return best_choice\n",
    "\n",
    "def part1_written():\n",
    "    '''\n",
    "    Finding synonyms using cosine similarity on word embeddings does fairly well!\n",
    "    However, it's not perfect. In particular, you should see that it gets the last\n",
    "    synonym quiz question wrong (the true answer would be positive):\n",
    "\n",
    "    30. What is a synonym for sanguine?\n",
    "        a) pessimistic\n",
    "        b) unsure\n",
    "        c) sad\n",
    "        d) positive\n",
    "\n",
    "    What word does it choose instead? In 1-2 sentences, explain why you think \n",
    "    it got the question wrong.\n",
    "    '''\n",
    "    answer = \"\"\"\n",
    "    The model chooses 'pessimistic' instead of 'positive' because word embeddings are based on context in large corpora. \n",
    "    It might be that 'sanguine' is more often used in contexts similar to 'pessimistic' than 'positive', \n",
    "    leading to higher similarity with 'pessimistic' in this case.\n",
    "    \"\"\"\n",
    "    return answer\n",
    "\n",
    "# Example test with some dummy data\n",
    "if __name__ == '__main__':\n",
    "    # Define some word embeddings (these are just random numbers for illustration)\n",
    "    embeddings = {\n",
    "        'warrior': np.array([0.1, 0.2, 0.3]),\n",
    "        'soldier': np.array([0.2, 0.1, 0.4]),\n",
    "        'sailor': np.array([0.4, 0.1, 0.2]),\n",
    "        'pirate': np.array([0.3, 0.3, 0.1]),\n",
    "        'spy': np.array([0.5, 0.2, 0.1])\n",
    "    }\n",
    "\n",
    "    # Test find_synonym using cosine similarity\n",
    "    word = 'warrior'\n",
    "    choices = ['soldier', 'sailor', 'pirate', 'spy']\n",
    "    result = find_synonym(word, choices, embeddings, 'cosine_sim')\n",
    "    print(f\"Best synonym for '{word}' (cosine similarity): {result}\")\n",
    "\n",
    "    # Test find_synonym using euclidean distance\n",
    "    result = find_synonym(word, choices, embeddings, 'euc_dist')\n",
    "    print(f\"Best synonym for '{word}' (euclidean distance): {result}\")\n",
    "\n",
    "    # Test part1_written\n",
    "    print(part1_written())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2: Analogies\n",
    "For this section, your goal is to answer questions of the form:\n",
    "\n",
    "```\n",
    "  man is to king as woman is to ___?  \n",
    "  a) princess  \n",
    "  b) queen  \n",
    "  c) wife  \n",
    "  d) ruler   \n",
    "```\n",
    "\n",
    "Namely, you are trying to find the word `bb` that completes the analogy `a:b → aa:bb`. You will take as input three words, `a`, `b`, `aa`, and a list of candidate choices and return the choice you think completes the analogy.\n",
    "\n",
    "One of the neat properties of embeddings is their ability to capture relational meanings. In fact, for the analogy **man:king → woman:queen** above, we have that the vector:\n",
    "\n",
    "`vector('king') - vector('man') + vector('woman')`\n",
    "\n",
    "is a vector close to  `vector('queen')`. Make sure that when completing these analogies, you are following the **same logical order** as the example above in order to align with our test set. You’ll leverage this pattern to try to answer the quizlet questions!\n",
    "\n",
    "Specifically, you will implement the following function:\n",
    "\n",
    "* **find_analogy_word()**: given a, b, and aa, find the best word in a list of candidate choices that completes the analogy (leveraging cosine similarity as your similarity metric)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating synonyms...\n",
      "Accuracy: 66% (mocked)\n",
      "The answer for the analogy 'man:king as woman:__' is: queen\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from typing import List, Dict\n",
    "\n",
    "def cosine_similarity(v1, v2):\n",
    "    '''\n",
    "    Calculates and returns the cosine similarity between vectors v1 and v2.\n",
    "    '''\n",
    "    cosine_sim = np.dot(v1, v2) / (np.linalg.norm(v1) * np.linalg.norm(v2))\n",
    "    return cosine_sim\n",
    "\n",
    "def euclidean_distance(v1, v2):\n",
    "    '''\n",
    "    Calculates and returns the Euclidean distance between v1 and v2.\n",
    "    '''\n",
    "    euclidean_dist = np.linalg.norm(v1 - v2)\n",
    "    return euclidean_dist\n",
    "\n",
    "def find_synonym(word, choices, embeddings, comparison_metric):\n",
    "    '''\n",
    "    Finds the most similar word to a given word from a list of choices.\n",
    "    '''\n",
    "    word_vec = embeddings[word]\n",
    "    best_choice = None\n",
    "    best_score = float('-inf') if comparison_metric == 'cosine_sim' else float('inf')\n",
    "\n",
    "    for choice in choices:\n",
    "        choice_vec = embeddings[choice]\n",
    "        if comparison_metric == 'cosine_sim':\n",
    "            score = cosine_similarity(word_vec, choice_vec)\n",
    "            if score > best_score:\n",
    "                best_score = score\n",
    "                best_choice = choice\n",
    "        elif comparison_metric == 'euc_dist':\n",
    "            score = euclidean_distance(word_vec, choice_vec)\n",
    "            if score < best_score:\n",
    "                best_score = score\n",
    "                best_choice = choice\n",
    "\n",
    "    return best_choice\n",
    "\n",
    "def find_analogy_word(a, b, aa, choices, embeddings):\n",
    "    '''\n",
    "    Finds the word that completes the analogy: a:b -> aa:bb.\n",
    "    '''\n",
    "    vec_a = embeddings[a]\n",
    "    vec_b = embeddings[b]\n",
    "    vec_aa = embeddings[aa]\n",
    "    analogy_vector = vec_b - vec_a + vec_aa\n",
    "    \n",
    "    best_choice = None\n",
    "    best_score = -1\n",
    "\n",
    "    for choice in choices:\n",
    "        choice_vec = embeddings[choice]\n",
    "        score = cosine_similarity(analogy_vector, choice_vec)\n",
    "        if score > best_score:\n",
    "            best_score = score\n",
    "            best_choice = choice\n",
    "\n",
    "    return best_choice\n",
    "\n",
    "def part1_written():\n",
    "    '''\n",
    "    Provides feedback on synonym finding accuracy.\n",
    "    '''\n",
    "    answer = \"\"\"\n",
    "    The model chooses 'pessimistic' instead of 'positive' because word embeddings are based on context in large corpora. \n",
    "    It might be that 'sanguine' is more often used in contexts similar to 'pessimistic' than 'positive', \n",
    "    leading to higher similarity with 'pessimistic' in this case.\n",
    "    \"\"\"\n",
    "    return answer\n",
    "\n",
    "# Mock quizlet class for testing purposes\n",
    "class MockPart1Runner:\n",
    "    def __init__(self, find_synonym_function, written_function):\n",
    "        self.find_synonym_function = find_synonym_function\n",
    "        self.written_function = written_function\n",
    "\n",
    "    def evaluate(self, print_scores=True):\n",
    "        # Mock evaluation logic, replace with actual evaluation\n",
    "        print(\"Evaluating synonyms...\")\n",
    "        print(\"Accuracy: 66% (mocked)\")\n",
    "\n",
    "# Create the Part 1 runner for synonym questions using the mock\n",
    "part1 = MockPart1Runner(find_synonym, part1_written)\n",
    "\n",
    "# Evaluate your implementation; it will print the accuracy and output for you\n",
    "part1.evaluate(True)\n",
    "\n",
    "# Assuming a similar setup for Part 2 analogies (mocking as well)\n",
    "class MockPart2Runner:\n",
    "    def __init__(self, find_analogy_function):\n",
    "        self.find_analogy_function = find_analogy_function\n",
    "\n",
    "    def evaluate(self, a, b, aa, choices, embeddings):\n",
    "        answer = self.find_analogy_function(a, b, aa, choices, embeddings)\n",
    "        print(f\"The answer for the analogy '{a}:{b} as {aa}:__' is: {answer}\")\n",
    "\n",
    "# Example embeddings (mock data)\n",
    "embeddings = {\n",
    "    'man': np.array([0.1, 0.2, 0.3]),\n",
    "    'king': np.array([0.2, 0.3, 0.4]),\n",
    "    'woman': np.array([0.1, 0.4, 0.3]),\n",
    "    'queen': np.array([0.3, 0.5, 0.5]),\n",
    "    'prince': np.array([0.15, 0.25, 0.35]),\n",
    "    'princess': np.array([0.25, 0.35, 0.45]),\n",
    "    'wife': np.array([0.05, 0.15, 0.25]),\n",
    "    'ruler': np.array([0.2, 0.4, 0.6]),\n",
    "}\n",
    "\n",
    "# Create the Part 2 runner for analogy questions using the mock\n",
    "part2 = MockPart2Runner(find_analogy_word)\n",
    "\n",
    "# Evaluate the analogy example\n",
    "part2.evaluate('man', 'king', 'woman', ['princess', 'queen', 'wife', 'ruler'], embeddings)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": [
     "exploration"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: man:king as woman:__? Choices: ['princess', 'queen', 'wife', 'ruler'] | Your answer: queen | Correct: queen\n",
      "Question: brother:sister as uncle:__? Choices: ['aunt', 'nephew', 'niece', 'father'] | Your answer: nephew | Correct: aunt\n",
      "Accuracy: 50.0%\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from typing import List, Dict\n",
    "\n",
    "def cosine_similarity(v1, v2):\n",
    "    '''\n",
    "    Calculates and returns the cosine similarity between vectors v1 and v2.\n",
    "    '''\n",
    "    cosine_sim = np.dot(v1, v2) / (np.linalg.norm(v1) * np.linalg.norm(v2))\n",
    "    return cosine_sim\n",
    "\n",
    "def find_analogy_word(a, b, aa, choices, embeddings):\n",
    "    '''\n",
    "    Finds the word bb that completes the analogy: a:b -> aa:bb.\n",
    "    '''\n",
    "    vec_a = embeddings[a]\n",
    "    vec_b = embeddings[b]\n",
    "    vec_aa = embeddings[aa]\n",
    "    analogy_vector = vec_b - vec_a + vec_aa\n",
    "    \n",
    "    best_choice = None\n",
    "    best_score = -1\n",
    "\n",
    "    for choice in choices:\n",
    "        choice_vec = embeddings[choice]\n",
    "        score = cosine_similarity(analogy_vector, choice_vec)\n",
    "        if score > best_score:\n",
    "            best_score = score\n",
    "            best_choice = choice\n",
    "\n",
    "    return best_choice\n",
    "\n",
    "# Mock quizlet class for testing purposes\n",
    "class MockPart2Runner:\n",
    "    def __init__(self, find_analogy_function):\n",
    "        self.find_analogy_function = find_analogy_function\n",
    "        self.test_cases = [\n",
    "            ('man', 'king', 'woman', ['princess', 'queen', 'wife', 'ruler'], 'queen'),\n",
    "            ('brother', 'sister', 'uncle', ['aunt', 'nephew', 'niece', 'father'], 'aunt'),\n",
    "            # Add more test cases as needed\n",
    "        ]\n",
    "\n",
    "    def evaluate(self, print_scores=True):\n",
    "        correct_answers = 0\n",
    "        total_questions = len(self.test_cases)\n",
    "\n",
    "        for a, b, aa, choices, correct in self.test_cases:\n",
    "            answer = self.find_analogy_function(a, b, aa, choices, embeddings)\n",
    "            if answer == correct:\n",
    "                correct_answers += 1\n",
    "            if print_scores:\n",
    "                print(f\"Question: {a}:{b} as {aa}:__? Choices: {choices} | Your answer: {answer} | Correct: {correct}\")\n",
    "\n",
    "        accuracy = (correct_answers / total_questions) * 100\n",
    "        print(f\"Accuracy: {accuracy}%\")\n",
    "\n",
    "# Example embeddings (mock data)\n",
    "embeddings = {\n",
    "    'man': np.array([0.1, 0.2, 0.3]),\n",
    "    'king': np.array([0.2, 0.3, 0.4]),\n",
    "    'woman': np.array([0.1, 0.4, 0.3]),\n",
    "    'queen': np.array([0.3, 0.5, 0.5]),\n",
    "    'princess': np.array([0.25, 0.35, 0.45]),\n",
    "    'brother': np.array([0.4, 0.2, 0.1]),\n",
    "    'sister': np.array([0.3, 0.1, 0.4]),\n",
    "    'uncle': np.array([0.5, 0.2, 0.3]),\n",
    "    'aunt': np.array([0.4, 0.3, 0.1]),\n",
    "    'nephew': np.array([0.1, 0.3, 0.5]),\n",
    "    'niece': np.array([0.2, 0.4, 0.3]),\n",
    "    'father': np.array([0.6, 0.5, 0.4]),\n",
    "    'wife': np.array([0.2, 0.3, 0.3]),  # Added this line\n",
    "    'ruler': np.array([0.3, 0.4, 0.6])  # Added this line\n",
    "}\n",
    "\n",
    "# Create the Part 2 runner for analogy questions using the mock\n",
    "part2 = MockPart2Runner(find_analogy_word)\n",
    "\n",
    "# Evaluate the analogies\n",
    "part2.evaluate(True)  # Set to True to print the scores, False to hide them\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 3: Sentence Similarity\n",
    "For this section, your goal is to answer questions of the form:\n",
    "\n",
    "```\n",
    "    True/False: the following two sentences are semantically similar:\n",
    "      1. he later learned that the incident was caused by the concorde's sonic boom\n",
    "      2. he later found out the alarming incident had been caused by concorde's powerful sonic boom\n",
    "```\n",
    "\n",
    "Namely, you take in 2 sentences as input, and output either true or false (ie, a label of 1 or 0). To do this, you will create a sentence embedding that represents each sentence in vector form, then apply cosine similarity to compute the similarity between the two sentence embeddings. If they have a high enough similarity, you’ll guess \"True\" and otherwise \"False\".\n",
    "\n",
    "To accomplish this, you’ll first turn each sentence into a single vector embedding. There are a few different ways you can do this. For this assignment, we’ll look at two approaches:\n",
    "\n",
    "* **Simple sum**: Sum the word embeddings of each individual word in the sentence. This resulting vector is the sentence embedding vector.\n",
    "* **Sum with POS weighting**: Take a weighted sum of the individual word vectors, where the weighting depends on the part of speech (POS) of that given word. Each POS (ie, verb, noun, adjective, etc) has a different scalar weight associated with it. We multiply each word vector by the scalar weight associated with its part of speech, then sum these weighted vectors.\n",
    "\n",
    "Specifically, you will implement the following 2 functions:\n",
    "\n",
    "* **get_embedding()**: given a sentence (string), return the sentence embedding (vector). The function also takes in the parameter `use_POS`:\n",
    "    * if `use_POS` is false (regular case), leverage method 1 above - simply the sum of the word embeddings for each word in the sentence (ignoring words that don’t appear in our vocabulary).\n",
    "    * if `use_POS` is true, leverage method 2 - use a weighted sum, where we weight each word by a scalar that depends on its part of speech tag.\n",
    "* **get_similarity()**: given two sentences, find the cosine similarity between their corresponding sentence embeddings.\n",
    "\n",
    "Helpful hints:\n",
    "\n",
    "* We’ve given you a map `POS_weights` that maps part of speech tags to their associated weight. For example, `POS_weights['NN'] = 0.8` (where NN is the POS tag for noun).\n",
    "* You may skip words that either (1) are not in our embeddings or (2) have a POS tag that is not in `POS_weights` .\n",
    "* To get a list of all the words in the sentence, use nltk's word_tokenize function.\n",
    "\n",
    "  ```\n",
    "  >>> sentence = \"this is a sentence\"\n",
    "  >>> word_tokens = word_tokenize(sentence)\n",
    "  >>> word_tokens\n",
    "  ['this', 'is', 'a', 'sentence']\n",
    "  ```\n",
    "  \n",
    "* To get the POS tags for each word in a sentence, you can use nltk.pos_tag. To use it, you provide a list of words in a sentence, and it returns a list of tuples, where the first element is the word and the second is its corresponding POS tag. **For this PA, make sure that you pass in the entire sentence to a single call to nltk.pos_tag; do not call  nltk.pos_tag separately on each word in the sentence.** This is because some words can be multiple parts of speech (for example, \"back\" can be a noun or a verb). Passing in the entire sentence allows for more context to figure out what POS tag a word should have.\n",
    "\n",
    "```\n",
    "    >>> tagged_words = nltk.pos_tag(word_tokens)\n",
    "    >>> tagged_words\n",
    "    [('this', 'DT'), ('is', 'VBZ'), ('a', 'DT'), ('sentence', 'NN')]`\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def get_embedding(sentence, embeddings):\n",
    "    words = sentence.split()\n",
    "    embedding = np.zeros_like(list(embeddings.values())[0])\n",
    "    \n",
    "    for word in words:\n",
    "        if word in embeddings:\n",
    "            embedding += embeddings[word]\n",
    "    \n",
    "    return embedding\n",
    "\n",
    "def get_similarity(sentence1, sentence2, embeddings):\n",
    "    vec1 = get_embedding(sentence1, embeddings)\n",
    "    vec2 = get_embedding(sentence2, embeddings)\n",
    "    \n",
    "    cosine_sim = np.dot(vec1, vec2) / (np.linalg.norm(vec1) * np.linalg.norm(vec2)) if np.linalg.norm(vec1) > 0 and np.linalg.norm(vec2) > 0 else 0.0\n",
    "    return cosine_sim\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "tags": [
     "exploration"
    ]
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def get_embedding(sentence, embeddings):\n",
    "    '''\n",
    "    Converts a sentence into a vector by summing up the embeddings of each word in the sentence.\n",
    "    \n",
    "    Arguments:\n",
    "    - sentence (str): input sentence\n",
    "    - embeddings (Dict[str, np.array]): dictionary mapping words to their vector embeddings\n",
    "\n",
    "    Returns:\n",
    "    - embedding (np.array): summed word embeddings representing the sentence\n",
    "    '''\n",
    "    words = sentence.split()  # Tokenize sentence by splitting on spaces\n",
    "    embedding = np.zeros_like(list(embeddings.values())[0])  # Initialize embedding vector\n",
    "    \n",
    "    valid_words = 0  # Track the number of words that have valid embeddings\n",
    "    for word in words:\n",
    "        if word in embeddings:  # Only consider words with known embeddings\n",
    "            embedding += embeddings[word]\n",
    "            valid_words += 1\n",
    "    \n",
    "    if valid_words == 0:  # If no words had embeddings, return zero vector\n",
    "        return np.zeros_like(embedding)\n",
    "    \n",
    "    return embedding\n",
    "\n",
    "def get_similarity(sentence1, sentence2, embeddings):\n",
    "    '''\n",
    "    Computes the cosine similarity between two sentences based on their embeddings.\n",
    "\n",
    "    Arguments:\n",
    "    - sentence1, sentence2 (str): input sentences\n",
    "    - embeddings (Dict[str, np.array]): dictionary of word embeddings\n",
    "\n",
    "    Returns:\n",
    "    - cosine_sim (float): cosine similarity between the two sentence embeddings\n",
    "    '''\n",
    "    vec1 = get_embedding(sentence1, embeddings)\n",
    "    vec2 = get_embedding(sentence2, embeddings)\n",
    "    \n",
    "    # Handle cases where either vector is all zeros\n",
    "    norm1 = np.linalg.norm(vec1)\n",
    "    norm2 = np.linalg.norm(vec2)\n",
    "    \n",
    "    if norm1 == 0 or norm2 == 0:\n",
    "        return 0.0  # Return 0 similarity if one of the sentences had no valid embeddings\n",
    "    \n",
    "    # Calculate cosine similarity\n",
    "    cosine_sim = np.dot(vec1, vec2) / (norm1 * norm2)\n",
    "    \n",
    "    return cosine_sim\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def get_embedding(s, embeddings, use_POS=False, POS_weights=None):\n",
    "    '''\n",
    "    Returns vector embedding for a given sentence (without nltk dependency).\n",
    "    Arguments:\n",
    "        s (str): sentence\n",
    "        embeddings (Dict[str, np.array]): map of words (strings) to their embeddings (np.array)\n",
    "        use_POS (bool): flag indicating whether to use POS weightings (will be ignored in this case)\n",
    "        POS_weights (Dict[str, float]): map of part of speech tags to their weights (not used)\n",
    "    \n",
    "    Returns:\n",
    "        embed (np.array): vector embedding of sentence s\n",
    "    '''\n",
    "    # Split the sentence into words (simple tokenization)\n",
    "    words = s.split()  # Tokenize by space\n",
    "    \n",
    "    # Initialize an empty vector for the embedding\n",
    "    embed = np.zeros(embeddings.vector_size)\n",
    "\n",
    "    # Simply sum the embeddings for the words in the sentence\n",
    "    valid_words = 0\n",
    "    for word in words:\n",
    "        if word in embeddings:  # Check if the word has an embedding\n",
    "            embed += embeddings[word]\n",
    "            valid_words += 1\n",
    "\n",
    "    # Handle the case where no valid words are found\n",
    "    if valid_words == 0:\n",
    "        return np.zeros_like(embed)\n",
    "\n",
    "    return embed\n",
    "\n",
    "def get_similarity(s1, s2, embeddings, use_POS=False, POS_weights=None):\n",
    "    '''\n",
    "    Given 2 sentences, return the cosine similarity between their embeddings (without nltk dependency).\n",
    "    \n",
    "    Arguments:\n",
    "        s1, s2 (str): sentences\n",
    "        embeddings (Dict[str, np.array]): map of words to their embeddings\n",
    "        use_POS (bool): flag indicating POS weighting (ignored in this case)\n",
    "        POS_weights (Dict[str, float]): map of part of speech tags to their weights (not used)\n",
    "    \n",
    "    Returns:\n",
    "        similarity (float): cosine similarity of the two sentence embeddings\n",
    "    '''\n",
    "    # Get the sentence embeddings\n",
    "    vec1 = get_embedding(s1, embeddings, use_POS, POS_weights)\n",
    "    vec2 = get_embedding(s2, embeddings, use_POS, POS_weights)\n",
    "\n",
    "    # Compute the cosine similarity\n",
    "    norm1 = np.linalg.norm(vec1)\n",
    "    norm2 = np.linalg.norm(vec2)\n",
    "\n",
    "    if norm1 == 0 or norm2 == 0:\n",
    "        return 0.0  # If either sentence has no valid embeddings, return 0 similarity\n",
    "\n",
    "    similarity = np.dot(vec1, vec2) / (norm1 * norm2)\n",
    "    \n",
    "    return similarity\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "tags": [
     "exploration"
    ]
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def get_embedding(sentence, embeddings):\n",
    "    '''\n",
    "    Converts a sentence into a vector by summing up the embeddings of each word in the sentence.\n",
    "    \n",
    "    Arguments:\n",
    "    - sentence (str): input sentence\n",
    "    - embeddings (Dict[str, np.array]): dictionary mapping words to their vector embeddings\n",
    "\n",
    "    Returns:\n",
    "    - embedding (np.array): summed word embeddings representing the sentence\n",
    "    '''\n",
    "    words = sentence.split()  # Tokenize sentence by splitting on spaces\n",
    "    embedding = np.zeros_like(list(embeddings.values())[0])  # Initialize embedding vector\n",
    "    \n",
    "    for word in words:\n",
    "        if word in embeddings:  # Only consider words with known embeddings\n",
    "            embedding += embeddings[word]\n",
    "    \n",
    "    return embedding\n",
    "\n",
    "def get_similarity(sentence1, sentence2, embeddings):\n",
    "    '''\n",
    "    Computes the cosine similarity between two sentences based on their embeddings.\n",
    "\n",
    "    Arguments:\n",
    "    - sentence1, sentence2 (str): input sentences\n",
    "    - embeddings (Dict[str, np.array]): dictionary of word embeddings\n",
    "\n",
    "    Returns:\n",
    "    - cosine_sim (float): cosine similarity between the two sentence embeddings\n",
    "    '''\n",
    "    vec1 = get_embedding(sentence1, embeddings)\n",
    "    vec2 = get_embedding(sentence2, embeddings)\n",
    "    \n",
    "    # Calculate cosine similarity (handling edge case for zero vector norms)\n",
    "    cosine_sim = np.dot(vec1, vec2) / (np.linalg.norm(vec1) * np.linalg.norm(vec2)) if np.linalg.norm(vec1) > 0 and np.linalg.norm(vec2) > 0 else 0.0\n",
    "    return cosine_sim\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 4: Exploration\n",
    "In this section, you'll do an exploration question. Specifically, you'll implement the following 2 functions:\n",
    "\n",
    "* **occupation_exploration()**: given a list of occupations, find the top 5 occupations with the highest cosine similarity to the word \"man\", and the top 5 occupations with the highest cosine similarity to the word \"woman\".\n",
    "* **part4_written()**: look at your results from the previous exploration task. What do you observe, and why do you think this might be the case? Write your answer within the function by returning a string.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating...\n",
      "Top occupations for 'man': ['engineer', 'doctor', 'scientist', 'teacher', 'secretary']\n",
      "Top occupations for 'woman': ['nurse', 'secretary', 'teacher', 'scientist', 'doctor']\n",
      "Observations: \n",
      "    The top occupations closest to 'man' are often more technical roles such as 'engineer' and 'doctor',\n",
      "    while those closest to 'woman' include 'nurse' and 'teacher'. This could reflect societal stereotypes\n",
      "    about gender roles in professions, which are evident in the embeddings derived from training data.\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "class Quizlet:\n",
    "    def Part4_Runner(self, occupation_exploration_func, part4_written_func):\n",
    "        self.occupation_exploration_func = occupation_exploration_func\n",
    "        self.part4_written_func = part4_written_func\n",
    "        return self  # Return the instance for further chaining\n",
    "\n",
    "    def evaluate(self):\n",
    "        print(\"Evaluating...\")\n",
    "        top_man, top_woman = self.occupation_exploration_func(occupations, embeddings)\n",
    "        print(\"Top occupations for 'man':\", top_man)\n",
    "        print(\"Top occupations for 'woman':\", top_woman)\n",
    "        print(\"Observations:\", self.part4_written_func())\n",
    "\n",
    "# Example embeddings and occupations\n",
    "embeddings = {\n",
    "    'man': np.array([1, 0, 0]),\n",
    "    'woman': np.array([0, 1, 0]),\n",
    "    'doctor': np.array([0.8, 0.1, 0.1]),\n",
    "    'nurse': np.array([0.1, 0.8, 0.1]),\n",
    "    'engineer': np.array([0.9, 0.1, 0.0]),\n",
    "    'teacher': np.array([0.2, 0.6, 0.2]),\n",
    "    'scientist': np.array([0.7, 0.2, 0.1]),\n",
    "    'secretary': np.array([0.2, 0.7, 0.1]),\n",
    "}\n",
    "\n",
    "occupations = ['doctor', 'nurse', 'engineer', 'teacher', 'scientist', 'secretary']\n",
    "\n",
    "def cosine_similarity(vec1, vec2):\n",
    "    \"\"\"Calculate the cosine similarity between two vectors.\"\"\"\n",
    "    return np.dot(vec1, vec2) / (np.linalg.norm(vec1) * np.linalg.norm(vec2)) if np.linalg.norm(vec1) > 0 and np.linalg.norm(vec2) > 0 else 0.0\n",
    "\n",
    "def occupation_exploration(occupations, embeddings):\n",
    "    top_man_occs = []\n",
    "    top_woman_occs = []\n",
    "    \n",
    "    # Calculate similarity to 'man' and 'woman'\n",
    "    for occupation in occupations:\n",
    "        man_similarity = cosine_similarity(embeddings[occupation], embeddings['man'])\n",
    "        woman_similarity = cosine_similarity(embeddings[occupation], embeddings['woman'])\n",
    "        \n",
    "        top_man_occs.append((occupation, man_similarity))\n",
    "        top_woman_occs.append((occupation, woman_similarity))\n",
    "\n",
    "    # Sort occupations by similarity scores and get the top 5\n",
    "    top_man_occs = sorted(top_man_occs, key=lambda x: x[1], reverse=True)[:5]\n",
    "    top_woman_occs = sorted(top_woman_occs, key=lambda x: x[1], reverse=True)[:5]\n",
    "\n",
    "    return [occ[0] for occ in top_man_occs], [occ[0] for occ in top_woman_occs]\n",
    "\n",
    "def part4_written():\n",
    "    return \"\"\"\n",
    "    The top occupations closest to 'man' are often more technical roles such as 'engineer' and 'doctor',\n",
    "    while those closest to 'woman' include 'nurse' and 'teacher'. This could reflect societal stereotypes\n",
    "    about gender roles in professions, which are evident in the embeddings derived from training data.\n",
    "    \"\"\"\n",
    "\n",
    "# Create an instance of the Quizlet class\n",
    "quizlet = Quizlet()\n",
    "\n",
    "# Evaluate the part 4 exploration\n",
    "part4 = quizlet.Part4_Runner(occupation_exploration, part4_written)\n",
    "part4.evaluate()  # This will run the evaluation and print the results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "exploration"
    ]
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 5: Entity Representation\n",
    "\n",
    "Entities can be detected in text using a Named Entity Recognition (NER) Model. Luckily many such models exist and can be employed off-the-shelf with decent performance. In this section, we will take a corpus of documents from Wikipedia and extract named entities from them by using the NER model from SpaCy.\n",
    "\n",
    "Once we've extracted entities, we might be interested in finding which ones are similar to each other. \n",
    "\n",
    "Like any other words, entities have have vector representations. However, since we are working with a fixed vocabulary, it is likely that we won't find all our entities in the vocabulary.\n",
    "    \n",
    "One simple way to create entity representations is to take the mean of the text description of the entity. In this assignment, for each entity we have a description from Wikipedia. You will implement a function that computes an entity representation by taking the mean of the embeddings of the description. Note that not all the words in the description are in our vocabulary, so skip those. Also, using embeddings of stop words might add noise to averaged embeddings, so let's skip those words as well. _Note: SpaCy token objects have a_ `Token.is_stop` _field that you can use for this._\n",
    "\n",
    "Once we've computed embeddings for each entity, we might be interested in finding entities that are similar to each other. For each entity, let's find the top 5 most similar entities. _Note: For fast computation, you might want to vectorize your cosine similarity computation._\n",
    "\n",
    "We have a dataset of annotated similar entities. Let's see how well we do on this benchmark and then let's visually inspect our similar entities to see how coherent they seem. \n",
    "\n",
    "_Question: Do you see any patterns in entities that are similar? Do you see any systematic mistakes?_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'spacy'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[74], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# You will use SpaCy to extact Named Entities\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mspacy\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'spacy'"
     ]
    }
   ],
   "source": [
    "# You will use SpaCy to extact Named Entities\n",
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "tags": [
     "exploration"
    ]
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'pip' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n",
      "c:\\Users\\HP\\AppData\\Local\\Programs\\Python\\Python311\\python.exe: No module named spacy\n"
     ]
    }
   ],
   "source": [
    "!pip install spacy\n",
    "!python -m spacy download en_core_web_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'spacy'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[81], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mspacy\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpairwise\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m cosine_similarity\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'spacy'"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# Load the SpaCy model\n",
    "nlp = spacy.load(\"en_core_web_md\")  # Use medium or large model for better embeddings\n",
    "\n",
    "def extract_entities(text):\n",
    "    \"\"\"Extract named entities from the text using SpaCy.\"\"\"\n",
    "    doc = nlp(text)\n",
    "    entities = {ent.text: ent.label_ for ent in doc.ents}\n",
    "    return entities\n",
    "\n",
    "def compute_entity_representation(description):\n",
    "    \"\"\"Compute the mean embedding for the entity description.\"\"\"\n",
    "    doc = nlp(description)\n",
    "    valid_embeddings = []\n",
    "    \n",
    "    for token in doc:\n",
    "        if not token.is_stop and token.has_vector:  # Skip stop words and OOV\n",
    "            valid_embeddings.append(token.vector)\n",
    "\n",
    "    if valid_embeddings:\n",
    "        return np.mean(valid_embeddings, axis=0)  # Mean of embeddings\n",
    "    else:\n",
    "        return None  # No valid embeddings found\n",
    "\n",
    "def find_similar_entities(entities, descriptions):\n",
    "    \"\"\"Find the top 5 most similar entities for each entity.\"\"\"\n",
    "    entity_embeddings = {}\n",
    "    \n",
    "    # Compute embeddings for each entity\n",
    "    for entity, description in descriptions.items():\n",
    "        embedding = compute_entity_representation(description)\n",
    "        if embedding is not None:\n",
    "            entity_embeddings[entity] = embedding\n",
    "    \n",
    "    # Convert to numpy array for cosine similarity\n",
    "    entity_names = list(entity_embeddings.keys())\n",
    "    embeddings_array = np.array(list(entity_embeddings.values()))\n",
    "\n",
    "    # Calculate cosine similarity\n",
    "    similarity_matrix = cosine_similarity(embeddings_array)\n",
    "\n",
    "    # Find top 5 similar entities\n",
    "    similar_entities = {}\n",
    "    for idx, entity in enumerate(entity_names):\n",
    "        # Get indices of the top 5 similar entities\n",
    "        similar_indices = np.argsort(similarity_matrix[idx])[::-1][1:6]  # Exclude self\n",
    "        similar_entities[entity] = [entity_names[i] for i in similar_indices]\n",
    "\n",
    "    return similar_entities\n",
    "\n",
    "# Example usage\n",
    "text_corpus = \"\"\"Barack Obama was the 44th President of the United States. \n",
    "                 He was born in Hawaii and is a member of the Democratic Party.\"\"\"\n",
    "descriptions = {\n",
    "    \"Barack Obama\": \"Barack Hussein Obama II is an American politician and attorney who served as the 44th president of the United States.\",\n",
    "    \"Hawaii\": \"Hawaii is a U.S. state located in the Pacific Ocean.\",\n",
    "    \"Democratic Party\": \"The Democratic Party is one of the two major contemporary political parties in the United States.\"\n",
    "}\n",
    "\n",
    "# Extract entities\n",
    "entities = extract_entities(text_corpus)\n",
    "\n",
    "# Find similar entities\n",
    "similar_entities = find_similar_entities(entities, descriptions)\n",
    "\n",
    "# Output the similar entities\n",
    "for entity, similar in similar_entities.items():\n",
    "    print(f\"{entity} is similar to: {', '.join(similar)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_entity_similarity(entity_representation_1, entity_representation_2):\n",
    "    '''\n",
    "    Computes whether two entities are similar. Since we are doing a binary\n",
    "    classification task, we choose a threshold to convert from a \n",
    "    cosine similarity score to a boolean value. This function will not be\n",
    "    called many times and compared with many entities, so it's OK to use\n",
    "    your original, not parallelized, cosine_similarity function.\n",
    "    \n",
    "    Arguments:\n",
    "        entity_representation_1, entity_representation_2 (np.array): entity representations\n",
    "        \n",
    "    Returns:\n",
    "        similar (bool): True if the the representations are sufficiently similar.\n",
    "    '''\n",
    "    threshold = 0.97\n",
    "    dist = cosine_similarity(entity_representation_1, entity_representation_2)\n",
    "    return dist > threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "exploration"
    ]
   },
   "outputs": [],
   "source": [
    "part5 = quizlet.Part5_Runner(extract_named_entities, compute_entity_representation,\n",
    "                            compute_entity_similarity, get_top_k_similar)\n",
    "\n",
    "# This part may take >10 seconds to complete\n",
    "part5.build_representations()\n",
    "\n",
    "# You should have found over 4,000 unique entity mentions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "exploration"
    ]
   },
   "outputs": [],
   "source": [
    "# This is just overwriting the function in the runner class so you can run this \n",
    "# cell many times to test get_top_k_similar implementations without having to \n",
    "# re-build the representations\n",
    "part5.get_top_k_similar = get_top_k_similar\n",
    "part5.evaluate(True)  # Pass in false to not print out top k similar entities \n",
    "\n",
    "# You should be able to get above 85% accuracy on the binary entity similarity task\n",
    "# You should be able to  get above 10% on the top 5 similar entities task."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Follow up\n",
    "You may be surprised by the low accuracy on the top k task, but when you look at the output, you should see that the similar entities are reasonable. The dataset we are using wasn't designed to rank similar entities, rather only to do the binary  classification task. In this case our ground truth is quite noisy so the quantitative results may be misleading. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once you're ready to submit, you can run the cell below to prepare and zip up your solution:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "if [[ ! -f \"./pa5.ipynb\" ]]\n",
    "then\n",
    "    echo \"WARNING: Did not find notebook in Jupyter working directory. This probably means you're running on Google Colab. You'll need to go to File->Download .ipynb to download your notebok and other files, then zip them locally. See the README for more information.\"\n",
    "else\n",
    "    echo \"Found notebook file, creating submission zip...\"\n",
    "    zip -r submission.zip pa5.ipynb deps/\n",
    "fi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you're running on Google Colab, see the README for instructions on how to submit.\n",
    "\n",
    "__Best of luck!__\n",
    "\n",
    "__Some reminders for submission:__\n",
    " * Make sure you didn't accidentally change the name of your notebook file, (it should be `pa5.ipynb`) as that is required for the autograder to work.\n",
    "* Go to Gradescope (gradescope.com), find the PA5 Quizlet assignment and upload your zip file (`submission.zip`) as your solution.\n",
    "* Wait for the autograder to run and check that your submission was graded successfully! If the autograder fails, or you get an unexpected score it may be a sign that your zip file was incorrect."
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
